{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize a BigQuery client\n",
        "# In Colab Enterprise, this will automatically authenticate using your project's credentials.\n",
        "client = bigquery.Client()\n",
        "\n",
        "# Define your BigQuery table reference\n",
        "project_id = 'youtube-content-optimize'\n",
        "dataset_id = 'streaming_data'\n",
        "table_id = 'youtube_video_stats'\n",
        "\n",
        "# Construct your SQL query\n",
        "# You can select all columns, or specify only the ones you need.\n",
        "# Add a WHERE clause, ORDER BY, or LIMIT as necessary for your analysis.\n",
        "query = f\"\"\"\n",
        "    SELECT *\n",
        "    FROM `{project_id}.{dataset_id}.{table_id}`\n",
        "    -- Optionally, add a LIMIT for testing or if you only need a subset of data\n",
        "    -- LIMIT 1000\n",
        "\"\"\"\n",
        "\n",
        "# Run the query and convert the results to a Pandas DataFrame\n",
        "# .to_dataframe() is a convenient method for direct conversion.\n",
        "try:\n",
        "    df = client.query(query).to_dataframe()\n",
        "    print(f\"Successfully loaded {len(df)} rows into a Pandas DataFrame.\")\n",
        "    print(df.head()) # Display the first few rows of the DataFrame\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK_avEyqlAJA",
        "outputId": "b372f77c-dc9f-4fcc-a0f9-41bd02eec56d"
      },
      "id": "pK_avEyqlAJA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 200 rows into a Pandas DataFrame.\n",
            "      video_id                                              title  \\\n",
            "0  _n_XmyEhSNY                                   PRESIDENT - RAGE   \n",
            "1  zHyt69mJnj8        Friday Night Funkin - Mobile Launch Trailer   \n",
            "2  qebbMeyU_C4  Mellow Rackz & Youngboy Never Broke Again - Gu...   \n",
            "3  DVuiem6wG1s  $0 to $1 Trillion Using ONLY PRISMATIC Seeds i...   \n",
            "4  xxNFkHzwAA0  College Graduates VS Dropouts Debate: Is Colle...   \n",
            "\n",
            "           published_at      channel_title                channel_id  \\\n",
            "0  2025-07-17T23:00:06Z          PRESIDENT  UCCAxEuKZzOWyUZHFzuoTcjA   \n",
            "1  2025-07-21T15:09:32Z  FridayNightFunkin  UC9RfC_6a8t8MaN9GwFSjG1A   \n",
            "2  2025-07-19T13:04:04Z       Mellow Rackz  UC8adG-r_HDAI9edf6WR66fA   \n",
            "3  2025-07-19T03:10:54Z        peach plays  UCubCKTdlEsDrWGIlMEgX_Sg   \n",
            "4  2025-07-18T20:30:11Z               FaZe  UCTevXUV9L6_hgvFlLDMmf1w   \n",
            "\n",
            "          channel_published_at       channel_name  subscriber_count  \\\n",
            "0   2025-01-01T14:14:54.15094Z          PRESIDENT             69200   \n",
            "1  2024-02-25T05:46:14.974838Z  FridayNightFunkin            147000   \n",
            "2  2021-01-08T06:43:54.344452Z       Mellow Rackz             32600   \n",
            "3   2024-12-20T18:05:01.15634Z        peach plays            323000   \n",
            "4   2024-05-10T20:26:58.72194Z               FaZe            493000   \n",
            "\n",
            "   video_count  view_count  like_count  comment_count  duration caption  \\\n",
            "0            4      327478       20135           2377    PT4M9S   false   \n",
            "1           15      326235       45437           3766   PT1M43S   false   \n",
            "2           17      761013       46137           3162   PT2M54S   false   \n",
            "3           37     1773078       11393           2035  PT21M22S   false   \n",
            "4           40     1511141       47248           4805  PT49M20S   false   \n",
            "\n",
            "   licensed_content                                               tags  \\\n",
            "0              True                                                      \n",
            "1             False                   FNF, friday night funkin, mobile   \n",
            "2             False                                                      \n",
            "3              True  peach roblox, peach plays roblox, peach plays ...   \n",
            "4              True                                                      \n",
            "\n",
            "                 retrieved_at  duration_seconds  \n",
            "0  2025-07-22T07:38:14.704339             249.0  \n",
            "1  2025-07-22T07:38:05.038845             103.0  \n",
            "2  2025-07-22T07:38:05.838664             174.0  \n",
            "3  2025-07-22T07:38:09.431392            1282.0  \n",
            "4  2025-07-22T07:38:07.996489            2960.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure both are timezone-naive\n",
        "df['publishedAt'] = pd.to_datetime(df['published_at'], errors='coerce').dt.tz_localize(None)\n",
        "\n",
        "today = pd.to_datetime('today').tz_localize(None)\n",
        "\n",
        "df['days_since_published'] = (today - df['publishedAt']).dt.days"
      ],
      "metadata": {
        "id": "9yM8ij-hIsUV"
      },
      "id": "9yM8ij-hIsUV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoid division by zero\n",
        "import numpy as np\n",
        "df['channel_published_at'] = pd.to_datetime(df['channel_published_at'], errors='coerce').dt.tz_localize(None)\n",
        "today = pd.to_datetime('today').tz_localize(None)\n",
        "df['channel_published_at'] = (today - df['channel_published_at']).dt.days\n",
        "df['channel_age_days'] = df['channel_published_at'].replace(0, np.nan)\n",
        "\n",
        "# subscriber_growth_rate = subscriberCount / channel_age_days\n",
        "df['subscriber_growth_rate'] = df['subscriber_count'] / df['channel_age_days']\n",
        "\n",
        "# upload_frequency = videoCount / channel_age_days\n",
        "df['upload_frequency'] = df['video_count'] / df['channel_age_days']\n",
        "\n",
        "# views_per_upload = viewCount / videoCount\n",
        "df['views_per_upload'] = df['view_count'] / df['video_count']\n",
        "\n",
        "# engagement_per_upload = (likeCount + commentCount) / videoCount\n",
        "df['engagement_per_upload'] = (df['like_count'] + df['comment_count']) / df['video_count']\n",
        "\n",
        "# subscriber_per_upload = subscriberCount / videoCount\n",
        "df['subscriber_per_upload'] = df['subscriber_count'] / df['video_count']\n",
        "\n",
        "# Replace infinite and NaN values with 0 for downstream clustering/regression\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "df.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "-mc1vTRmPyCJ"
      },
      "id": "-mc1vTRmPyCJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['log_subscriber_growth_rate'] = np.log1p(df['subscriber_growth_rate'])\n",
        "df['log_upload_frequency'] = np.log1p(df['upload_frequency'])\n",
        "df['log_views_per_upload'] = np.log1p(df['views_per_upload'])\n",
        "df['log_engagement_per_upload'] = np.log1p(df['engagement_per_upload'])\n",
        "df['log_subscriber_per_upload'] = np.log1p(df['subscriber_per_upload'])"
      ],
      "metadata": {
        "id": "du6PPdCe-2x6"
      },
      "id": "du6PPdCe-2x6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def safe_parse_tags(tag_str):\n",
        "    if isinstance(tag_str, list):\n",
        "        return tag_str\n",
        "    if not isinstance(tag_str, str):\n",
        "        return []\n",
        "    # Match content inside brackets and split by comma\n",
        "    if tag_str.startswith(\"[\") and tag_str.endswith(\"]\"):\n",
        "        try:\n",
        "            inner = tag_str[1:-1]\n",
        "            tags = re.split(r',\\s*', inner)\n",
        "            tags = [t.strip(\" '\\\"\") for t in tags if t.strip()]\n",
        "            return tags\n",
        "        except Exception:\n",
        "            return []\n",
        "    return []\n",
        "\n",
        "df['tags_list'] = df['tags'].apply(safe_parse_tags)\n",
        "df['tags_joined'] = df['tags_list'].apply(lambda tags: ' '.join(tags))\n"
      ],
      "metadata": {
        "id": "t3a1tuYR8083"
      },
      "id": "t3a1tuYR8083",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=300)\n",
        "tags_tfidf = vectorizer.fit_transform(df['tags_joined'])\n"
      ],
      "metadata": {
        "id": "XjlkfqiY80HN"
      },
      "id": "XjlkfqiY80HN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# 1. Choose numeric features and scale them\n",
        "numeric_features = ['view_count', 'duration_seconds', 'log_subscriber_growth_rate', 'log_upload_frequency', 'log_views_per_upload', 'log_engagement_per_upload', 'log_subscriber_per_upload', 'days_since_published']\n",
        "scaled_numeric = StandardScaler().fit_transform(df[numeric_features])\n",
        "\n",
        "# 2. Combine numeric and text features\n",
        "X_combined = hstack([scaled_numeric, tags_tfidf])  # use sparse hstack for efficiency\n",
        "\n",
        "# 3. Apply PCA for dimensionality reduction\n",
        "pca = PCA(n_components=8) # Choose the number of components\n",
        "X_reduced = pca.fit_transform(X_combined.toarray()) # Convert to dense array for PCA\n",
        "\n",
        "# 4. Run KMeans clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "df['cluster'] = kmeans.fit_predict(X_reduced)\n"
      ],
      "metadata": {
        "id": "opYlp11pAHs6"
      },
      "id": "opYlp11pAHs6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_summary = df.groupby('cluster')[numeric_features].mean()\n",
        "print(cluster_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b562gyqFTTAe",
        "outputId": "d85d1349-1c3e-420d-8118-bdd8ffa7309f"
      },
      "id": "b562gyqFTTAe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             view_count  duration_seconds  log_subscriber_growth_rate  \\\n",
            "cluster                                                                 \n",
            "0        1006370.293333           1259.12                    0.158288   \n",
            "1              355232.6            655.40                    3.467877   \n",
            "2        4242935.083333           1110.25                    0.720471   \n",
            "\n",
            "         log_upload_frequency  log_views_per_upload  \\\n",
            "cluster                                               \n",
            "0                    0.003864              4.536429   \n",
            "1                    0.222323              4.097647   \n",
            "2                    0.002069              8.254914   \n",
            "\n",
            "         log_engagement_per_upload  log_subscriber_per_upload  \\\n",
            "cluster                                                         \n",
            "0                         1.263215                   5.053408   \n",
            "1                         0.931712                   4.898361   \n",
            "2                         5.143069                   8.802026   \n",
            "\n",
            "         days_since_published  \n",
            "cluster                        \n",
            "0                    4.373333  \n",
            "1                    3.400000  \n",
            "2                    5.258333  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#number of rows in a cluster\n",
        "df['cluster'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "aYaTrDzJA5XF",
        "outputId": "fd1492cd-c11a-487e-d6eb-3ae0ce875cc3"
      },
      "id": "aYaTrDzJA5XF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cluster\n",
              "2    120\n",
              "0     75\n",
              "1      5\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df['log_view_count'] = np.log1p(df['view_count'])\n",
        "df['log_duration_seconds'] = np.log1p(df['duration_seconds'])\n",
        "\n",
        "# === 1. Select log-transformed predictor variables ===\n",
        "X = df[['log_duration_seconds', 'log_subscriber_growth_rate',\n",
        "        'log_subscriber_per_upload', 'log_upload_frequency',\n",
        "        'log_views_per_upload', 'log_engagement_per_upload']]\n",
        "\n",
        "# === 2. Target variable: log_subscriber_growth_rate ===\n",
        "y = df['log_view_count']\n",
        "\n",
        "# === 3. Train-test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# === 4. Train linear regression model ===\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === 5. Predict and evaluate ===\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate MSE without squared=False, then take the square root for RMSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"RMSE: {rmse:.3f}\")\n",
        "print(f\"R²: {r2:.3f}\")\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': model.coef_\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(coef_df)\n",
        "\n",
        "df.to_csv(\"cleaned_youtube_data.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv--vNoFDbUE",
        "outputId": "a34b56a6-02cb-4742-e705-217cb1f4a813"
      },
      "id": "Iv--vNoFDbUE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1.119\n",
            "R²: 0.319\n",
            "                      Feature  Coefficient\n",
            "3        log_upload_frequency     1.827799\n",
            "4        log_views_per_upload     0.719673\n",
            "5   log_engagement_per_upload    -0.533039\n",
            "1  log_subscriber_growth_rate    -0.197604\n",
            "0        log_duration_seconds    -0.146589\n",
            "2   log_subscriber_per_upload     0.116599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"cleaned_youtube_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "lLeY0PusN62J"
      },
      "id": "lLeY0PusN62J",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "sblouie (Jul 22, 2025, 8:50:16 PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
